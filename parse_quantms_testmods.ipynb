{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modification</th>\n",
       "      <th>Total PSMs</th>\n",
       "      <th>Percentage Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deamidation</td>\n",
       "      <td>246222</td>\n",
       "      <td>9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deamidation_plus_pyroglu</td>\n",
       "      <td>249786</td>\n",
       "      <td>11.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>default</td>\n",
       "      <td>224143</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oxidationW</td>\n",
       "      <td>227556</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pyroglu</td>\n",
       "      <td>227386</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quantms</td>\n",
       "      <td>242778</td>\n",
       "      <td>8.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modification  Total PSMs  Percentage Increase\n",
       "0               deamidation      246222                 9.85\n",
       "1  deamidation_plus_pyroglu      249786                11.44\n",
       "2                   default      224143                 0.00\n",
       "3                oxidationW      227556                 1.52\n",
       "4                   pyroglu      227386                 1.45\n",
       "5                   quantms      242778                 8.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "\"\"\"\n",
    "script in order to work must be in dir: script/parent_folder/idfilter/.log_files\n",
    "what script does: 1. for each parent_folder, for each idfilter folder, for each log_file, it takes spectra_num (number of spectra) found after filtering (check fourth comment in the bash code below)\n",
    "2. for each parent_folder, it sums the different spectra_num and that's it. 3. then concats all the sums in a df and calcs the %change based on the default sum\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Run the bash cell and capture the output\n",
    "result = subprocess.run(\n",
    "    ['bash', '-c', '''\n",
    "        # Loop through each folder in the parent directory\n",
    "        for dir in */idfilter; do\n",
    "    # Check if the idfilter/log_files directory exists and contains .log files\n",
    "    if [ -d \"$dir\" ] && ls \"$dir\"/*.log 1> /dev/null 2>&1; then\n",
    "        total=0  # Initialize a total variable for the current directory\n",
    "        # Loop through each log file in the idfilter/log_files directory\n",
    "        for file in \"$dir\"/*.log; do\n",
    "            if [[ -f \"$file\" ]]; then\n",
    "                # Extract the number from the next-to-last line\n",
    "                num=$(tail -n 2 \"$file\" | head -n 1 | awk '{print $1}')\n",
    "                \n",
    "                # Check if the extracted value is a number and add it to the total\n",
    "                if [[ \"$num\" =~ ^[0-9]+$ ]]; then\n",
    "                    total=$((total + num))\n",
    "                else\n",
    "                    echo \"Warning: Skipping file $file due to non-numeric value '$num'\"\n",
    "                fi\n",
    "            fi\n",
    "        done\n",
    "        \n",
    "        # Extract and print the parent directory name\n",
    "        parent_dir=$(basename $(dirname \"$dir\"))\n",
    "        echo \"${parent_dir} $total\"\n",
    "    fi\n",
    "done\n",
    "    '''], \n",
    "    capture_output=True, \n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Split the output into lines\n",
    "output_lines = result.stdout.split('\\n')\n",
    "\n",
    "# Parse the output and create a list of dictionaries\n",
    "data = []\n",
    "for line in output_lines:\n",
    "    if ' ' in line:\n",
    "        dir_name, total_sum = line.split(' ')\n",
    "        data.append({'Modification': dir_name, 'Total PSMs': int(total_sum)})\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "# Get the 'Total' value for the 'default' row\n",
    "default_total = df.loc[df['Modification'] == 'default', 'Total PSMs'].values[0]\n",
    "\n",
    "# Calculate the percentage increase for each row based on the 'default' row\n",
    "df['Percentage Increase'] = ((df['Total PSMs'] - default_total) / default_total) * 100\n",
    "df['Percentage Increase'] = df['Percentage Increase'].round(2)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Proteins Before</th>\n",
       "      <th>Proteins After</th>\n",
       "      <th>Spectra Before</th>\n",
       "      <th>Spectra After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E26698_2p_50uPAC12_trap10_PRC-5442_2_consensus...</td>\n",
       "      <td>14122</td>\n",
       "      <td>6018</td>\n",
       "      <td>55560</td>\n",
       "      <td>35587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B28545_Ap_IonOpt_PRC-6063__newprep_6_10ul_cons...</td>\n",
       "      <td>19897</td>\n",
       "      <td>6399</td>\n",
       "      <td>70672</td>\n",
       "      <td>29760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B28549_Ap_IonOpt_PRC-6063__newprep_2_10ul_cons...</td>\n",
       "      <td>16212</td>\n",
       "      <td>3561</td>\n",
       "      <td>40249</td>\n",
       "      <td>13877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B28553_Ap_IonOpt_PRC-6063__newprep_4_10ul_cons...</td>\n",
       "      <td>17204</td>\n",
       "      <td>5184</td>\n",
       "      <td>53628</td>\n",
       "      <td>23187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B28551_Ap_IonOpt_PRC-6063__newprep_3_10ul_cons...</td>\n",
       "      <td>17198</td>\n",
       "      <td>2950</td>\n",
       "      <td>47871</td>\n",
       "      <td>13922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E28115_1p_50uPAC13__trap9_PRC-5590_1_consensus...</td>\n",
       "      <td>11450</td>\n",
       "      <td>5607</td>\n",
       "      <td>58630</td>\n",
       "      <td>45060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B28547_Ap_IonOpt_PRC-6063_newprep_1_10ul_conse...</td>\n",
       "      <td>17424</td>\n",
       "      <td>3376</td>\n",
       "      <td>47429</td>\n",
       "      <td>14424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B28543_Ap_IonOpt_PRC-6063__newprep_5_10ul_cons...</td>\n",
       "      <td>19501</td>\n",
       "      <td>6492</td>\n",
       "      <td>69999</td>\n",
       "      <td>30394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E26704_2p_50uPAC12_trap10_PRC-5442_5_consensus...</td>\n",
       "      <td>13966</td>\n",
       "      <td>6725</td>\n",
       "      <td>56949</td>\n",
       "      <td>39460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Total</td>\n",
       "      <td>146974</td>\n",
       "      <td>46312</td>\n",
       "      <td>500987</td>\n",
       "      <td>245671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  Proteins Before  \\\n",
       "0  E26698_2p_50uPAC12_trap10_PRC-5442_2_consensus...            14122   \n",
       "1  B28545_Ap_IonOpt_PRC-6063__newprep_6_10ul_cons...            19897   \n",
       "2  B28549_Ap_IonOpt_PRC-6063__newprep_2_10ul_cons...            16212   \n",
       "3  B28553_Ap_IonOpt_PRC-6063__newprep_4_10ul_cons...            17204   \n",
       "4  B28551_Ap_IonOpt_PRC-6063__newprep_3_10ul_cons...            17198   \n",
       "5  E28115_1p_50uPAC13__trap9_PRC-5590_1_consensus...            11450   \n",
       "6  B28547_Ap_IonOpt_PRC-6063_newprep_1_10ul_conse...            17424   \n",
       "7  B28543_Ap_IonOpt_PRC-6063__newprep_5_10ul_cons...            19501   \n",
       "8  E26704_2p_50uPAC12_trap10_PRC-5442_5_consensus...            13966   \n",
       "9                                              Total           146974   \n",
       "\n",
       "   Proteins After  Spectra Before  Spectra After  \n",
       "0            6018           55560          35587  \n",
       "1            6399           70672          29760  \n",
       "2            3561           40249          13877  \n",
       "3            5184           53628          23187  \n",
       "4            2950           47871          13922  \n",
       "5            5607           58630          45060  \n",
       "6            3376           47429          14424  \n",
       "7            6492           69999          30394  \n",
       "8            6725           56949          39460  \n",
       "9           46312          500987         245671  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#give an idfilter path w/ log files and get the sum of proteins and spectra before and after filtering\n",
    "\n",
    "import os, re\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Directory containing the .log files\n",
    "directory = '../noMBR/idfilter'\n",
    "\n",
    "# Regular expressions to extract the needed data\n",
    "protein_re = re.compile(r'with (\\d+) proteins')\n",
    "spectra_re = re.compile(r'(\\d+) spectra identified')\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".log\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            # Try to extract proteins and spectra counts\n",
    "            proteins_matches = protein_re.findall(content)\n",
    "            spectra_matches = spectra_re.findall(content)\n",
    "            \n",
    "            # Check if we have at least two matches for proteins and spectra\n",
    "            if len(proteins_matches) >= 2 and len(spectra_matches) >= 2:\n",
    "                proteins_before = proteins_matches[0]\n",
    "                proteins_after = proteins_matches[1]\n",
    "                spectra_before = spectra_matches[0]\n",
    "                spectra_after = spectra_matches[1]\n",
    "\n",
    "                # Append the results to the data list\n",
    "                data.append([filename, proteins_before, proteins_after, spectra_before, spectra_after])\n",
    "            else:\n",
    "                # Log files that don't match the expected format\n",
    "                print(f\"Warning: '{filename}' does not have the expected format.\")\n",
    "                # Optionally append a placeholder row for missing data\n",
    "                data.append([filename, 'N/A', 'N/A', 'N/A', 'N/A'])\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df1 = pd.DataFrame(data, columns=['Filename', 'Proteins Before', 'Proteins After', 'Spectra Before', 'Spectra After'])\n",
    "\n",
    "# Convert the relevant columns to numeric\n",
    "df1[['Proteins Before', 'Proteins After', 'Spectra Before', 'Spectra After']] = df1[['Proteins Before', 'Proteins After', 'Spectra Before', 'Spectra After']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Calculate the sum for each numeric column\n",
    "sum_row = df1[['Proteins Before', 'Proteins After', 'Spectra Before', 'Spectra After']].sum()\n",
    "\n",
    "# Create a DataFrame for the sum row\n",
    "sum_row_df = pd.DataFrame(sum_row).T\n",
    "sum_row_df['Filename'] = 'Total'\n",
    "\n",
    "# Concatenate the sum row to the original DataFrame\n",
    "df1 = pd.concat([df1, sum_row_df], ignore_index=True)\n",
    "\n",
    "display(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.ncbi.nlm.nih.gov/datasets/genome/?taxon=5320\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read the HTML tables from the URL\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming the first table is the one you want\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#df = tables[0]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the DataFrame\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(df.head())\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1225\u001b[0m     [\n\u001b[1;32m   1226\u001b[0m         is_file_like(io),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     ]\n\u001b[1;32m   1231\u001b[0m ):\n\u001b[1;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/html.py:1003\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[1;32m   1005\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/html.py:983\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    972\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[1;32m    973\u001b[0m     io,\n\u001b[1;32m    974\u001b[0m     compiled_match,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m     storage_options,\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 983\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/html.py:249\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/html.py:598\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[0;34m(self, document, match, attrs)\u001b[0m\n\u001b[1;32m    596\u001b[0m tables \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mfind_all(element_name, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    600\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    601\u001b[0m unique_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://www.ncbi.nlm.nih.gov/datasets/genome/?taxon=5320\"\n",
    "\n",
    "# Read the HTML tables from the URL\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Assuming the first table is the one you want\n",
    "#df = tables[0]\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "junk after document element: line 2350, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[13], line 12\u001b[0m\n    tree = ET.ElementTree(ET.fromstring(content))\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/lib/python3.12/xml/etree/ElementTree.py:1330\u001b[0;36m in \u001b[0;35mXML\u001b[0;36m\n\u001b[0;31m    parser.feed(text)\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m junk after document element: line 2350, column 0\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load the XML file\n",
    "# Ensure the XML file is well-formed and does not contain extraneous characters or elements\n",
    "with open('../../../../Downloads/pleurotus_genomes.xml', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Remove any extraneous characters after the root element\n",
    "content = content.split('</root>')[0] + '</root>'\n",
    "\n",
    "# Parse the cleaned XML content\n",
    "tree = ET.ElementTree(ET.fromstring(content))\n",
    "root = tree.getroot()\n",
    "\n",
    "# Prepare a list to hold the extracted data\n",
    "genomes_data = []\n",
    "\n",
    "# FILEPATH: /home/pgiannikos/thesis/pci/secretomics/test_modifications/parse_quantms_testmods.ipynb\n",
    "\n",
    "# Iterate over each 'DocSum' element to extract the required fields\n",
    "for docsum in root.findall('DocSum'):\n",
    "    accession = docsum.find('Accession').text if docsum.find('Accession') is not None else ''\n",
    "    organism = docsum.find('Organism').text if docsum.find('Organism') is not None else ''\n",
    "    taxid = docsum.find('TaxId').text if docsum.find('TaxId') is not None else ''\n",
    "    assembly = docsum.find('Assembly').text if docsum.find('Assembly') is not None else ''\n",
    "    submitter = docsum.find('Submitter').text if docsum.find('Submitter') is not None else ''\n",
    "    pubmed_id = docsum.find('PubMedId').text if docsum.find('PubMedId') is not None else ''\n",
    "    status = docsum.find('Status').text if docsum.find('Status') is not None else ''\n",
    "    release_date = docsum.find('ReleaseDate').text if docsum.find('ReleaseDate') is not None else ''\n",
    "    technology = docsum.find('Technology').text if docsum.find('Technology') is not None else ''\n",
    "    project_id = docsum.find('ProjectID').text if docsum.find('ProjectID') is not None else ''\n",
    "    sample_id = docsum.find('SampleID').text if docsum.find('SampleID') is not None else ''\n",
    "    \n",
    "    # Append extracted data to the list\n",
    "    genomes_data.append([\n",
    "        accession, assembly, organism, taxid, submitter, pubmed_id,\n",
    "        status, release_date, technology, project_id, sample_id\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genomes_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenomes_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genomes_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(genomes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
